{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "PCA_SVM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chr1shr/am205_g_activities/blob/master/svd_image_processing/PCA_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnTS4EbaB6Jy"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pylab as plt \n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn import svm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB-jDzHVB6J6"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyIcYvkNB6J7"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n",
        "#normalize img data\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYQKJgoJB6KA"
      },
      "source": [
        "#check data shape\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay_WLXhnCjR8"
      },
      "source": [
        "This data represents 60000 images of numbers, each of them is an image of size 28 $\\times$ 28. We can convert it into 2-D matrix by flattening the image height and width. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trso0OCHB6KF"
      },
      "source": [
        "#dimensions\n",
        "n_samples, h, w = X_train.shape\n",
        "#flatten for PCA\n",
        "X_train_flat = X_train.reshape(n_samples, -1)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d55bIAPB6KF"
      },
      "source": [
        "# Fit PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxuzK7TxB6KI"
      },
      "source": [
        "def construct_pca(n_components, X_train_flat):\n",
        "    return PCA(n_components).fit(X_train_flat)\n",
        "\n",
        "pca = construct_pca(10, X_train_flat)#PCA(n_components=10).fit(X_train_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asautSiAB6KL"
      },
      "source": [
        "pca_sample = construct_pca(50, X_train_flat)\n",
        "#plot\n",
        "f, ax = plt.subplots(1,2, figsize=(20,6))\n",
        "ax[0].plot(pca_sample.explained_variance_ratio_)\n",
        "ax[0].set_title(\"PCA explained variance ratio\")\n",
        "ax[0].set_xlabel(\"n components\")\n",
        "ax[0].set_ylabel(\"variance ration\")\n",
        "\n",
        "ax[1].plot(np.cumsum(pca_sample.explained_variance_ratio_))\n",
        "ax[1].set_title(\"PCA explained variance ratio cumulative\")\n",
        "ax[1].set_xlabel(\"n components\")\n",
        "ax[1].set_ylabel(\"variance ration cumulative\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjR3uZaMB6KP"
      },
      "source": [
        "## First 10 components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsbQJ6FmB6KQ"
      },
      "source": [
        "fig, ax = plt.subplots(2, 5, figsize=(20, 10),\n",
        "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i in range(10):\n",
        "    ax[int(i/5), i%5].imshow(pca.components_[i].reshape((h,w)), cmap='gray')\n",
        "    ax[int(i/5), i%5].set_title('component: '+str(i+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_dCMvYQB6KS"
      },
      "source": [
        "## pca reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8gp1duMB6KS"
      },
      "source": [
        "components = pca.transform(X_train_flat)\n",
        "projected = pca.inverse_transform(components)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzDHQ8fsB6KU"
      },
      "source": [
        "fig, ax = plt.subplots(2, 10, figsize=(15, 3),\n",
        "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i in range(10):\n",
        "    ax[0, i].imshow(X_train_flat[i].reshape(h,w), cmap='gray')\n",
        "    ax[1, i].imshow(projected[i].reshape(h,w), cmap='gray')\n",
        "ax[0, 0].set_ylabel('full-dim\\ninput')\n",
        "ax[1, 0].set_ylabel('10-dim\\nreconstruction');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxZDNpVwB6KX"
      },
      "source": [
        "# Linear classifier: SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IojbqKd4B6KX"
      },
      "source": [
        "## Directly apply svm: 10 cases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwY1Ngk7B6KY"
      },
      "source": [
        "def draw_vector(v0, v1, ax=None):\n",
        "    ax = plt.gca()\n",
        "    arrowprops=dict(arrowstyle='->',\n",
        "                    linewidth=2,\n",
        "                    shrinkA=0, shrinkB=0)\n",
        "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
        "\n",
        "def draw_PCA_eig(reduced_data):\n",
        "    pca_test = PCA(n_components=2)\n",
        "    pca_test.fit(reduced_data)\n",
        "    for length, vector in zip(pca_test.explained_variance_, pca_test.components_):\n",
        "        v = vector * 2 * np.sqrt(length)\n",
        "        draw_vector(pca_test.mean_, pca_test.mean_ + v)\n",
        "\n",
        "def draw_sv_pca(data, savefig = False):\n",
        "    #get original data\n",
        "    X_train, X_test, y_train, y_test = data\n",
        "    pca_2 = PCA(n_components=2)\n",
        "    X_r = pca_2.fit(X_train).transform(X_train)\n",
        "    X_t = pca_2.fit(X_test).transform(X_test)\n",
        "    sv_pca = svm.SVC(kernel='linear', C=1).fit(X_r, y_train)\n",
        "    #plot\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    #plot original test data\n",
        "    plt.scatter(X_t[:, 0], X_t[:, 1], c=y_test, s=30, cmap=plt.cm.coolwarm)\n",
        "    #prepare grid for svm\n",
        "    x_min, x_max = X_t[:, 0].min() - 1, X_t[:, 0].max() + 1\n",
        "    y_min, y_max = X_t[:, 1].min() - 1, X_t[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                         np.arange(y_min, y_max, 0.02))#x, y coord\n",
        "    Z = sv_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    #plot svm\n",
        "    plt.contour(xx, yy, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,linestyles=['--', '-', '--'])\n",
        "    #plot pca\n",
        "    draw_PCA_eig(X_t)\n",
        "    if savefig:\n",
        "        plt.savefig('svm_pca.jpg')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ0vwaA2B6Kb"
      },
      "source": [
        "draw_sv_pca((X_train_flat, X_test_flat, y_train, y_test), False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ee1mX_0B6Kf"
      },
      "source": [
        "## Observation by pca and binary classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKpYyAvAB6Kf"
      },
      "source": [
        "import matplotlib.colors as mcolors\n",
        "color_choice = [i for i in mcolors.TABLEAU_COLORS]\n",
        "pca_latent_train = PCA(n_components=2).fit(X_train_flat).transform(X_train_flat)\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "    plt.scatter(x=pca_latent_train[:,0][np.where(y_train==i)], y=pca_latent_train[:,1][np.where(y_train==i)],\\\n",
        "               c=color_choice[i], label=i)\n",
        "plt.legend()\n",
        "plt.title('MNIST, First 2 principal components')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SokwsjZtG00E"
      },
      "source": [
        "It can be observed from above that the number 0 (orange) is far away from the number 1 (deep blue). So in principle, it should be easier to separate and classify the two numbers 0 and 1. Let's see how SVM works!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpiLuMMqXYj4"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(2):\n",
        "    plt.scatter(x=pca_latent_train[:,0][np.where(y_train==i)], y=pca_latent_train[:,1][np.where(y_train==i)],\\\n",
        "               c=color_choice[i], label=i)\n",
        "plt.legend()\n",
        "plt.title('MNIST 0 and 1, First 2 principal components')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP50S4XyB6Ki"
      },
      "source": [
        "# distinguishable 1 and 0\n",
        "X_train_flat_01 = X_train_flat[np.where(y_train<=1)]\n",
        "y_train_01 = y_train[np.where(y_train<=1)]\n",
        "X_test_flat_01 = X_test_flat[np.where(y_test<=1)]\n",
        "y_test_01 = y_test[np.where(y_test<=1)]\n",
        "draw_sv_pca((X_train_flat_01, X_test_flat_01, y_train_01, y_test_01))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LmTvEd2HUfL"
      },
      "source": [
        "Similarly, we find that the number 9 quite overlaps with the number 7, so it would not be surprising if the classifier barely classifies these two numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVoyQBOqB6Kj"
      },
      "source": [
        "# barely distinguishable 7 and 9\n",
        "X_train_flat_79 = X_train_flat[np.where((y_train>=7) & (y_train != 8))]\n",
        "y_train_79 = y_train[np.where((y_train>=7) & (y_train != 8))]\n",
        "X_test_flat_79 = X_test_flat[np.where((y_test>=7) & (y_test != 8))]\n",
        "y_test_79 = y_test[np.where((y_test>=7) & (y_test != 8))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-YgG-tYB6Kl"
      },
      "source": [
        "draw_sv_pca((X_train_flat_79, X_test_flat_79, y_train_79, y_test_79))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYQ4LM_vHmRE"
      },
      "source": [
        "Question: What would you say about number 6 and 8? Any other cases that would be easier/harder to classify based on the PCA plot?"
      ]
    }
  ]
}