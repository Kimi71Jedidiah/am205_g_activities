{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "QnTS4EbaB6Jy",
    "outputId": "1f2b3d62-7749-4d68-f744-9c817104645c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pylab as plt \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn import svm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dEokQ9GXCGSB",
    "outputId": "9f3c1a82-bfd1-4c8a-cde7-2b7135d56a3f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "Os7au9DsEKG0",
    "outputId": "fdc98b36-e5d7-4b1c-a338-6973f56832da"
   },
   "outputs": [],
   "source": [
    "#You may need to modify this based on your local path\n",
    "os.chdir('/content/gdrive/My Drive/Colab Notebooks/AM205_Activity')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pB-jDzHVB6J6"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "cyIcYvkNB6J7",
    "outputId": "819f7448-ca52-468b-fd57-5e0b9ba3997e"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n",
    "#normalize img data\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "qYQKJgoJB6KA",
    "outputId": "514b78b8-d247-4903-9873-b8a5e0fae88a"
   },
   "outputs": [],
   "source": [
    "#check data shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ay_WLXhnCjR8"
   },
   "source": [
    "This data represents 60000 images of numbers, each of them is an image of size 28 $\\times$ 28. We can convert it into 2-D matrix by flattening the image height and width. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Trso0OCHB6KF"
   },
   "outputs": [],
   "source": [
    "#dimensions\n",
    "n_samples, h, w = X_train.shape\n",
    "#flatten for PCA\n",
    "X_train_flat = X_train.reshape(n_samples, -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d55bIAPB6KF"
   },
   "source": [
    "# Fit PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KxuzK7TxB6KI"
   },
   "outputs": [],
   "source": [
    "def construct_pca(n_components, X_train_flat):\n",
    "    return PCA(n_components).fit(X_train_flat)\n",
    "\n",
    "pca = construct_pca(10, X_train_flat)#PCA(n_components=10).fit(X_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "asautSiAB6KL",
    "outputId": "991e674a-91fe-4b7c-f70d-f483db0b5229"
   },
   "outputs": [],
   "source": [
    "pca_sample = construct_pca(50, X_train_flat)\n",
    "#plot\n",
    "f, ax = plt.subplots(1,2, figsize=(20,6))\n",
    "ax[0].plot(pca_sample.explained_variance_ratio_)\n",
    "ax[0].set_title(\"PCA explained variance ratio\")\n",
    "ax[0].set_xlabel(\"n components\")\n",
    "ax[0].set_ylabel(\"variance ration\")\n",
    "\n",
    "ax[1].plot(np.cumsum(pca_sample.explained_variance_ratio_))\n",
    "ax[1].set_title(\"PCA explained variance ratio cumulative\")\n",
    "ax[1].set_xlabel(\"n components\")\n",
    "ax[1].set_ylabel(\"variance ration cumulative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjR3uZaMB6KP"
   },
   "source": [
    "## First 10 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "VsbQJ6FmB6KQ",
    "outputId": "41837770-f689-45c8-9061-9a1757d0eef4"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(20, 10),\n",
    "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i in range(10):\n",
    "    ax[int(i/5), i%5].imshow(pca.components_[i].reshape((h,w)), cmap='gray')\n",
    "    ax[int(i/5), i%5].set_title('component: '+str(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_dCMvYQB6KS"
   },
   "source": [
    "## pca reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8gp1duMB6KS"
   },
   "outputs": [],
   "source": [
    "components = pca.transform(X_train_flat)\n",
    "projected = pca.inverse_transform(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "KzDHQ8fsB6KU",
    "outputId": "63e806e6-1c3a-4ab3-ae10-da0c7b795993"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 10, figsize=(15, 3),\n",
    "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i in range(10):\n",
    "    ax[0, i].imshow(X_train_flat[i].reshape(h,w), cmap='gray')\n",
    "    ax[1, i].imshow(projected[i].reshape(h,w), cmap='gray')\n",
    "ax[0, 0].set_ylabel('full-dim\\ninput')\n",
    "ax[1, 0].set_ylabel('10-dim\\nreconstruction');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxZDNpVwB6KX"
   },
   "source": [
    "# Linear classifier: SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IojbqKd4B6KX"
   },
   "source": [
    "## Directly apply svm: 10 cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwY1Ngk7B6KY"
   },
   "outputs": [],
   "source": [
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0)\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
    "\n",
    "def draw_PCA_eig(reduced_data):\n",
    "    pca_test = PCA(n_components=2)\n",
    "    pca_test.fit(reduced_data)\n",
    "    for length, vector in zip(pca_test.explained_variance_, pca_test.components_):\n",
    "        v = vector * 2 * np.sqrt(length)\n",
    "        draw_vector(pca_test.mean_, pca_test.mean_ + v)\n",
    "\n",
    "def draw_sv_pca(data, savefig = False):\n",
    "    #get original data\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    pca_2 = PCA(n_components=2)\n",
    "    X_r = pca_2.fit(X_train).transform(X_train)\n",
    "    X_t = pca_2.fit(X_test).transform(X_test)\n",
    "    sv_pca = svm.SVC(kernel='linear', C=1).fit(X_r, y_train)\n",
    "    #plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    #plot original test data\n",
    "    plt.scatter(X_t[:, 0], X_t[:, 1], c=y_test, s=30, cmap=plt.cm.coolwarm)\n",
    "    #prepare grid for svm\n",
    "    x_min, x_max = X_t[:, 0].min() - 1, X_t[:, 0].max() + 1\n",
    "    y_min, y_max = X_t[:, 1].min() - 1, X_t[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))#x, y coord\n",
    "    Z = sv_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    #plot svm\n",
    "    plt.contour(xx, yy, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,linestyles=['--', '-', '--'])\n",
    "    #plot pca\n",
    "    draw_PCA_eig(X_t)\n",
    "    if savefig:\n",
    "        plt.savefig('svm_pca.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "MZ0vwaA2B6Kb",
    "outputId": "2be6b676-039a-4419-9821-4bc7e997bb89"
   },
   "outputs": [],
   "source": [
    "draw_sv_pca((X_train_flat, X_test_flat, y_train, y_test), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyLi5_cBB6Kd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ee1mX_0B6Kf"
   },
   "source": [
    "## Observation by pca and binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "id": "AKpYyAvAB6Kf",
    "outputId": "61220e20-5c93-4a8f-c107-e558d1fba557"
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "color_choice = [i for i in mcolors.TABLEAU_COLORS]\n",
    "pca_latent_train = PCA(n_components=2).fit(X_train_flat).transform(X_train_flat)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    plt.scatter(x=pca_latent_train[:,0][np.where(y_train==i)], y=pca_latent_train[:,1][np.where(y_train==i)],\\\n",
    "               c=color_choice[i], label=i)\n",
    "plt.legend()\n",
    "plt.title('MNIST, First 2 principal components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SokwsjZtG00E"
   },
   "source": [
    "It can be observed from above that the number 0 (orange) is far away from the number 1 (deep blue). So in principle, it should be easier to separate and classify the two numbers 0 and 1. Let's see how SVM works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "id": "xpiLuMMqXYj4",
    "outputId": "43d0232b-6cb4-485d-c4db-6bd3b4710c84"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(2):\n",
    "    plt.scatter(x=pca_latent_train[:,0][np.where(y_train==i)], y=pca_latent_train[:,1][np.where(y_train==i)],\\\n",
    "               c=color_choice[i], label=i)\n",
    "plt.legend()\n",
    "plt.title('MNIST 0 and 1, First 2 principal components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "NP50S4XyB6Ki",
    "outputId": "14a451cd-d585-49d6-a385-6b5ca491372b"
   },
   "outputs": [],
   "source": [
    "# distinguishable 1 and 0\n",
    "X_train_flat_01 = X_train_flat[np.where(y_train<=1)]\n",
    "y_train_01 = y_train[np.where(y_train<=1)]\n",
    "X_test_flat_01 = X_test_flat[np.where(y_test<=1)]\n",
    "y_test_01 = y_test[np.where(y_test<=1)]\n",
    "draw_sv_pca((X_train_flat_01, X_test_flat_01, y_train_01, y_test_01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LmTvEd2HUfL"
   },
   "source": [
    "Similarly, we find that the number 9 quite overlaps with the number 7, so it would not be surprising if the classifier barely classifies these two numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZVoyQBOqB6Kj"
   },
   "outputs": [],
   "source": [
    "# barely distinguishable 7 and 9\n",
    "X_train_flat_79 = X_train_flat[np.where((y_train>=7) & (y_train != 8))]\n",
    "y_train_79 = y_train[np.where((y_train>=7) & (y_train != 8))]\n",
    "X_test_flat_79 = X_test_flat[np.where((y_test>=7) & (y_test != 8))]\n",
    "y_test_79 = y_test[np.where((y_test>=7) & (y_test != 8))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "Q-YgG-tYB6Kl",
    "outputId": "301aa48b-0b22-497a-b71a-6a8ec7828664"
   },
   "outputs": [],
   "source": [
    "draw_sv_pca((X_train_flat_79, X_test_flat_79, y_train_79, y_test_79))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYQ4LM_vHmRE"
   },
   "source": [
    "Question: What would you say about number 6 and 8? Any other cases that would be easier/harder to classify based on the PCA plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ow7CvvkhB6Kn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6hpBGb8B6Ko"
   },
   "source": [
    "# Nonlinear classifier: nonlinear Autoencoder (provided as a model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "cw-TeqsMWTTk",
    "outputId": "9da6fecf-c71b-4c51-dc3a-fdd57c68be56"
   },
   "outputs": [],
   "source": [
    "Encoder = tf.keras.models.load_model('encoder_model')\n",
    "Encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbSghP4tIIDF"
   },
   "source": [
    "Here we provided a trained encoder model. It defines a latent space, and we can reconstrut the ten numbers in this space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "Hvmh-j47XHz8",
    "outputId": "3b524c27-7a58-4717-fb86-0fdb1ab77fb7"
   },
   "outputs": [],
   "source": [
    "ae_latent_train = Encoder.predict(X_train_flat)\n",
    "ae_latent_train_x = ae_latent_train[:,0]\n",
    "ae_latent_train_y = ae_latent_train[:,1]\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "color_choice = [i for i in mcolors.TABLEAU_COLORS]\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    plt.scatter(x=ae_latent_train[:,0][np.where(y_train==i)], y=ae_latent_train[:,1][np.where(y_train==i)],\\\n",
    "               c=color_choice[i], label=i)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQ527SkaXI89"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PCA_SVM.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
